{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Multi-Layer Perceptron\n",
    "Any neural network is simply a series of perceptrons feeding into one another. The perceptrons are arranged in layers with the outputs of a previous layer being the inputs into the next layer.\n",
    "\n",
    "With this in mind it seems that we did much of the heavy lifting in our [first notebook](./01. The Perceptron.ipynb) concerning the percepton - the single neuron emulating unit that is the building block of a neural network.\n",
    "\n",
    "In this workbook we will consider the simplest case of a fully-connected network. That is a network where each node (percepton) in a given layer is connected to every node in the subsequent layer. This means that the output of a perceptron in the first layer will therefore be an input into each perceptron in the next layer.\n",
    "\n",
    "![Neural Network Diagram](./img/neural-network.png \"A Fully Connected Neural Network\")\n",
    "\n",
    "## Expressiveness of Neural Networks\n",
    "\n",
    "## Training a Neural Network vs Training a Perceptron\n",
    "Similarly to the case of the vanilla perceptron we considered before, the values passed as inputs to each layer (and therefore each perceptron in that layer) will have weights associated with them. These weights will be the variables which we will vary as part of the training process with the ultimate goal of loss minimisation.\n",
    "\n",
    "In contrast to a single perceptron, a multi-layer perceptron must be trained in a more complex way since the weights in the first layer only have an indirect impact on the output albeit through many channels in a fully connected network. This indirect influence is difficult to trace through should the step activation function be kept. The discontinuous function is not differentiable and hence we are unable to perform what's known as backpropagation to calculate the impact of early layer weights on the ultimate output. Backpropagation is the algorithmic way of training a neural network. Errors in the output are traced back through the layers of the network and the weights are updated in turn in order to reduce the error. We will consider this process in detail later. \n",
    "\n",
    "In order to undertake backpropagation the error, or more specifically the model prediction, needs to be differentiable with respect to the weights. In order to achieve this, a smooth (differentiable) activation function is used in place of the perceptron step function.\n",
    "\n",
    "These functions are known as activation functions because they play the role of the activation threshold in the perceptron or the neuron being emulated. Popular choices are the sigmoid function, tanh and the Rectified Linear Unit function (ReLU).\n",
    "\n",
    "We will discuss the mathematics of backpropagation in detail [later](#backpropagation).\n",
    "\n",
    "\n",
    "## Activation Functions\n",
    "Activation functions determine how a perceptron produces its output. Unlike neurons, perceptrons are not limited to binary output and hence may produce any real number as their output. The choice of activation function can therefore shape this output by shaping the relationship between inputs and the output beyond the linear way in which weights enter the equation. This relationship change can be made for computational ease, to match the relationship we are trying to estimate or to aid in training the model.\n",
    "\n",
    "In the case of the neurons in our brains that the perceptrons aim to emulate, activation functions play the role of the activation threshold. In the brain the threshold is placed on a concentration gradient across a membrane which much reach a certain strength before an activation potential will be passed along the neuron. In our case, working in the mathematics of real numbers we need not limit ourselves to binary output. We may consider any output on the real domain. This can be considered the number of action potentials per second should one wish to maintain the biological parallels.\n",
    "\n",
    "### The Sigmoid Function\n",
    "A binary classifier may aim to place a probability on the given input belonging to a given class. This will mean that the outputs must, by way of being probabilities, fall in the unit interval ($o \\in [0,1]$). The sigmoid function will always produce outputs that are between 0 and 1 and can therefore be considered valid probabilities. The functional form of the sigmoid function is given below.\n",
    "\n",
    "$$\\sigma(x)=\\frac{1}{1+e^{-x}}$$\n",
    "\n",
    "<small><center><span style=\"color:gray\">*The Sigmoid Function*</span></center></small>\n",
    "\n",
    "\n",
    "Note that this function is strictly increasing in $x$ and varies from $0$ when $x$ is $-\\infty$ and 1 when $x$ is $\\infty$. It is smooth, defined for all real numbers and differentiable.\n",
    "\n",
    "Infact the differential takes a rather nice form which is one reason for the function's popularity. This will help us when training the model later on.\n",
    "\n",
    "\n",
    "$$\\sigma(x)=\\frac{1}{1+e^{-x}}$$\n",
    "<center><span style=\"color:gray\">*The Sigmoid Function*</span></center>\n",
    "\n",
    "Let's plot this function so that we can see what we're dealing with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll import our mathematical toolkit `numpy` and the plotting tools `matplotlib` and `seaborn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define our sigmoid function.\n",
    "\n",
    "Note that we decorate it with `numpy`'s `vectorize` function so that the function can be called on lists and arrays without further modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@np.vectorize\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let us generate some points and create a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x324 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-10, 10, 1000)\n",
    "y = sigmoid(x)\n",
    "plt.plot(x,y, figure=plt.figure(figsize=(9,4.5)))\n",
    "plt.axvline(0, color='k', lw=0.5)\n",
    "plt.xlabel('$x$', size=15)\n",
    "plt.ylabel('$\\sigma(x)$', size=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us find the differential by applying the quotient rule. \n",
    "\n",
    "$$\\frac{d\\frac{u}{v}}{dx}=\\frac{v\\frac{du}{dx} - u\\frac{dv}{dx}}{v^2}$$\n",
    "\n",
    "<small><center><span style=\"color:gray\">*The Quotient Rule*</span></center></small>\n",
    "\n",
    "This leads us to the following derivative of the sigmoid function.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sigma'(x) &=\\frac{e^{-x}}{(1+e^{-x})^2}\\\\&=\\frac{1}{1+e^{-x}}\\cdot \\frac{e^{-x}}{1+e^{-x}}\\\\&=\\frac{1}{1+e^{-x}}\\cdot\\frac{(1+e^{-x})-1}{1+e^{-x}}\\\\&=\\frac{1}{1+e^{-x}}\\cdot\\left(1-\\frac{1}{1+e^{-x}}\\right)\\\\&=\\sigma(x)(1-\\sigma(x))\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting A Problem To Solve\n",
    "\n",
    "To consider how neural networks work we need a set of data to learn from. In this case we will consider a a more complex classification problem wherein the outcome will be determined by some non-linear function of the inputs. This non-linear function is what we aim to learn with our network. First we must consider the relationship we wish to build. Let us consider a function of 5 variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 100 * np.random.random(10000)\n",
    "b = 50  * np.random.random(10000)\n",
    "c = 75  * np.random.random(10000)\n",
    "d = 10  * np.random.random(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us define a function of these five variables that generates a surface separating positive and negative examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@np.vectorize\n",
    "def hyperplane(a,b,c,d,e):\n",
    "    value = 1\n",
    "    if a > 75:\n",
    "        value *= np.sqrt(a)\n",
    "    if b < 10:\n",
    "        value += b\n",
    "    if c > 60 or d < 5:\n",
    "        value += c * d\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"build\"></a>\n",
    "## Building the Neural Network\n",
    "### The Forward Pass\n",
    "\n",
    "$$ prediction = w_{0,O}+\\sum_{j=1}^{n} w_{j,O}\\cdot \\sigma\\left(w_{0,j}+\\sum_{i=1}^{n} x_i w_{i,j}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\sum_{j=1}^n w_{j,O} x_{i} \\cdot \\sigma\\left(w_{0,j}+\\sum_{i=1}^n x_i w_{i,j}\\right)\\left(1 - \\sigma\\left(w_{0,j}+\\sum_{i=1}^n x_i w_{i,j}\\right)\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, weights):\n",
    "    x = np.insert(x, 0, 1)\n",
    "    output = x\n",
    "    for layer in weights[:-1]:\n",
    "        output = sigmoid(np.matmul(output, layer))\n",
    "        output = np.insert(output, 0, 1)\n",
    "    output = np.matmul(output, weights[-1])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intermediate_outputs(x, weights, layer):\n",
    "    x = np.insert(x, 0, 1)\n",
    "    output = x\n",
    "    full_network = False\n",
    "    if layer == len(weights):\n",
    "        layer -= 1\n",
    "        full_network = True\n",
    "    for i in range(layer):\n",
    "        output = sigmoid(np.matmul(output, weights[i]))\n",
    "        output = np.insert(output, 0, 1)\n",
    "    if full_network:\n",
    "        output = np.matmul(output, weights[-1])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = [\n",
    "        np.array([[1,1,1,1,1],\n",
    "        [2,2,2,2,2],\n",
    "        [3,3,3,3,3],\n",
    "        [4,4,4,4,4],\n",
    "        [5,5,5,5,5]]),\n",
    "        \n",
    "        np.array([[0.1],\n",
    "        [0.2],\n",
    "        [0.3],\n",
    "        [0.4],\n",
    "        [0.5],\n",
    "        [0.6]])\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.array([0.003, 0.19, 0.1, 0.39])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.06131809])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(i, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"backpropagation\"></a>\n",
    "## Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gradients(inputs, weights):\n",
    "    no_layers = len(weights)\n",
    "    predictions = predict(inputs, weights)\n",
    "    final_layer_derivatives = get_intermediate_outputs(inputs, weights, no_layers - 1)\n",
    "    first_layer_outputs = get_intermediate_outputs(inputs, weights, 1)\n",
    "    previous_layer_derivatives = np.array([])\n",
    "    for i in range(len(inputs) + 1):\n",
    "        for j in range(weights[-2].shape[1]):\n",
    "            if i == 0:\n",
    "                gradient = 1 * weights[-1][j]\n",
    "            else:\n",
    "                gradient = inputs[i-1] * weights[-1][j] * first_layer_outputs[j] * (1 - first_layer_outputs[j])\n",
    "            previous_layer_derivatives = np.append(previous_layer_derivatives, gradient)\n",
    "    previous_layer_derivatives = np.reshape(previous_layer_derivatives, weights[-2].shape)\n",
    "    return [previous_layer_derivatives, final_layer_derivatives]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1.00000000e-01, 2.00000000e-01, 3.00000000e-01, 4.00000000e-01,\n",
       "         5.00000000e-01],\n",
       "        [0.00000000e+00, 1.13801292e-05, 1.70701938e-05, 2.27602583e-05,\n",
       "         2.84503229e-05],\n",
       "        [0.00000000e+00, 7.20741514e-04, 1.08111227e-03, 1.44148303e-03,\n",
       "         1.80185379e-03],\n",
       "        [0.00000000e+00, 3.79337639e-04, 5.69006459e-04, 7.58675278e-04,\n",
       "         9.48344098e-04],\n",
       "        [0.00000000e+00, 1.47941679e-03, 2.21912519e-03, 2.95883358e-03,\n",
       "         3.69854198e-03]]),\n",
       " array([1.        , 0.98065905, 0.98065905, 0.98065905, 0.98065905,\n",
       "        0.98065905])]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_gradients(i, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(inputs, weights, true_values, epochs, eta):\n",
    "    w = np.copy(weights)\n",
    "    for _ in epochs:\n",
    "        for i, t in zip(inputs, true_values):\n",
    "            predictions = predict(i, w)\n",
    "            grads = calculate_gradients(i, w)\n",
    "            update = []\n",
    "            for layer_grad in grads:\n",
    "                update.append(-eta * (t - predictions) * layer_grad)\n",
    "            for l in range(len(w)):\n",
    "                w[l] += update[l]\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
